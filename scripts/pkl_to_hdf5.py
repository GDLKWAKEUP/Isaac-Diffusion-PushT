import os
import h5py
import pickle
import numpy as np
import glob
import argparse
import cv2
from tqdm import tqdm

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--input_dir', type=str, required=True, help="åŒ…å« pkl æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument('--output', type=str, default="data/isaac_pusht.hdf5", help="è¾“å‡ºçš„ hdf5 æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    # 1. æœé›† pkl æ–‡ä»¶
    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰å­æ–‡ä»¶å¤¹ä¸­çš„ pkl
    pkl_files = sorted(glob.glob(os.path.join(args.input_dir, "**/*.pkl"), recursive=True))
    print(f"ğŸ” æ‰¾åˆ° {len(pkl_files)} æ¡è½¨è¿¹æ•°æ®")

    if len(pkl_files) == 0:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
        return

    # 2. åˆ›å»º HDF5 æ–‡ä»¶
    # Robomimic æ ¼å¼è¦æ±‚ï¼šæ ¹ç›®å½•ä¸‹æœ‰ä¸€ä¸ª 'data' ç»„ï¼Œæ¯ä¸ª demo æ˜¯ 'demo_0', 'demo_1'...
    os.makedirs(os.path.dirname(args.output), exist_ok=True)
    f = h5py.File(args.output, "w")
    grp = f.create_group("data")

    total_samples = 0

    print("ğŸš€ å¼€å§‹è½¬æ¢...")
    for i, pkl_path in enumerate(tqdm(pkl_files)):
        with open(pkl_path, 'rb') as pkl_f:
            ep_data = pickle.load(pkl_f)

        # --- A. æ•°æ®é¢„å¤„ç† ---
        
        # 1. åŠ¨ä½œ (Action): (T, 8)
        actions = ep_data['actions'].astype(np.float32)
        
        # 2. çŠ¶æ€ (State): æ‹¼æ¥ Joint(7) + Gripper(1) -> (T, 8)
        joint_pos = ep_data['obs']['joint_pos']
        gripper = ep_data['obs']['gripper']
        # ç¡®ä¿ gripper æ˜¯ (T, 1)
        if gripper.ndim == 1:
            gripper = gripper[:, None]
        state = np.concatenate([joint_pos, gripper], axis=-1).astype(np.float32)

        # 3. å›¾åƒ (Image): ç¼©æ”¾ 256 -> 96
        # Global
        img_g_raw = ep_data['obs']['image_global'] # (T, 256, 256, 3)
        img_g_96 = []
        for img in img_g_raw:
            img_g_96.append(cv2.resize(img, (96, 96), interpolation=cv2.INTER_AREA))
        img_g_96 = np.array(img_g_96, dtype=np.uint8)
        # HWC -> CHW (Robomimic Dataset å†…éƒ¨é€šå¸¸ä¼šè‡ªåŠ¨è½¬ï¼Œå­˜ HWC æœ€é€šç”¨)
        # è¿™é‡Œæˆ‘ä»¬å­˜ HWC: (T, 96, 96, 3)

        # Wrist
        img_w_raw = ep_data['obs']['image_wrist']
        img_w_96 = []
        for img in img_w_raw:
            img_w_96.append(cv2.resize(img, (96, 96), interpolation=cv2.INTER_AREA))
        img_w_96 = np.array(img_w_96, dtype=np.uint8)

        # --- B. å†™å…¥ HDF5 ç»“æ„ ---
        # ç»“æ„: data/demo_i/obs/key
        
        demo_grp = grp.create_group(f"demo_{i}")
        
        # å†™å…¥æ€»æ­¥æ•°å±æ€§ (é‡è¦)
        demo_grp.attrs["num_samples"] = len(actions)
        total_samples += len(actions)

        # å†™å…¥ Observation
        obs_grp = demo_grp.create_group("obs")
        obs_grp.create_dataset("img_global", data=img_g_96)
        obs_grp.create_dataset("img_wrist", data=img_w_96)
        obs_grp.create_dataset("state", data=state) # 8ç»´çŠ¶æ€

        # å†™å…¥ Action
        demo_grp.create_dataset("actions", data=actions)
        
        # å†™å…¥ Rewards (å¯é€‰)
        demo_grp.create_dataset("rewards", data=ep_data['rewards'])

    # --- C. å†™å…¥å…¨å±€å…ƒæ•°æ® ---
    # Robomimic éœ€è¦çŸ¥é“æ€»æ ·æœ¬æ•°
    grp.attrs["total"] = total_samples
    
    # è¿˜æœ‰ä¸€ç§ metadata æ ¼å¼ï¼Œä¸ºäº†å…¼å®¹æ€§æœ€å¥½ä¹Ÿå†™ä¸Š
    if "mask" not in f:
        # åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„ maskï¼ŒåŒ…å«æ‰€æœ‰ demo
        mask_grp = f.create_group("mask")
        mask_grp.create_dataset("train", data=np.array([f"demo_{i}" for i in range(len(pkl_files))]).astype("S"))
        # (ç®€å•èµ·è§ï¼Œä¸åˆ†éªŒè¯é›†ï¼Œæˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨åˆ†)

    f.close()
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {args.output}")
    print(f"ğŸ“Š æ€»è½¨è¿¹æ•°: {len(pkl_files)}")
    print(f"â±ï¸ æ€»å¸§æ•°: {total_samples}")

if __name__ == "__main__":
    main()